{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generic data science libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# import scikit-learn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# models\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "from scipy import interp\n",
    "from itertools import cycle\n",
    "\n",
    "# metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.metrics import accuracy_score, classification_report, auc, confusion_matrix, roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(\"..\\data\\DallasAccidents.csv\")\n",
    "df = pd.read_csv(\"..\\..\\TexasAccidents.csv\")\n",
    "pd.set_option('display.max_columns', None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Street\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort Street Type\n",
    "df.loc[df['Street'].str.contains(' Ln'), 'Road_Type'] = 'Road'\n",
    "df.loc[df['Street'].str.contains(' Lane'), 'Road_Type'] = 'Road'\n",
    "df.loc[df['Street'].str.contains(' Way'), 'Road_Type'] = 'Road'\n",
    "df.loc[df['Street'].str.contains(' Sq'), 'Road_Type'] = 'Road'\n",
    "df.loc[df['Street'].str.contains(' Pl'), 'Road_Type'] = 'Road'\n",
    "df.loc[df['Street'].str.contains(' Plz'), 'Road_Type'] = 'Road'\n",
    "df.loc[df['Street'].str.contains(' Rd'), 'Road_Type'] = 'Road'\n",
    "df.loc[df['Street'].str.contains(' Road'), 'Road_Type'] = 'Road'\n",
    "df.loc[df['Street'].str.contains(' Dr'), 'Road_Type'] = 'Road'\n",
    "df.loc[df['Street'].str.contains(' Ave'), 'Road_Type'] = 'Road'\n",
    "df.loc[df['Street'].str.contains(' Trl'), 'Road_Type'] = 'Road'\n",
    "df.loc[df['Street'].str.contains(' Trail'), 'Road_Type'] = 'Road'\n",
    "df.loc[df['Street'].str.contains(' Blvd'), 'Road_Type'] = 'Road'\n",
    "df.loc[df['Street'].str.contains(' Boulevard'), 'Road_Type'] = 'Road'\n",
    "df.loc[df['Street'].str.contains(' St'), 'Road_Type'] = 'Road'\n",
    "df.loc[df['Street'].str.contains(' Cir'), 'Road_Type'] = 'Road'\n",
    "\n",
    "df.loc[df['Street'].str.contains('FM '), 'Road_Type'] = 'Road'\n",
    "df.loc[df['Street'].str.contains('Cr '), 'Road_Type'] = 'Road'\n",
    "\n",
    "df.loc[df['Street'].str.contains(' Hwy'), 'Road_Type'] = 'Highway'\n",
    "df.loc[df['Street'].str.contains('Highway'), 'Road_Type'] = 'Highway'\n",
    "df.loc[df['Street'].str.contains('US-'), 'Road_Type'] = 'Highway'\n",
    "df.loc[df['Street'].str.contains('Loop '), 'Road_Type'] = 'Highway'\n",
    "df.loc[df['Street'].str.contains(' Fwy'), 'Road_Type'] = 'Highway'\n",
    "df.loc[df['Street'].str.contains(' Freeway'), 'Road_Type'] = 'Highway'\n",
    "df.loc[df['Street'].str.contains(' Tollway'), 'Road_Type'] = 'Highway'\n",
    "df.loc[df['Street'].str.contains('TX-'), 'Road_Type'] = 'Highway'\n",
    "df.loc[df['Street'].str.contains('I-'), 'Road_Type'] = 'Highway'\n",
    "df.loc[df['Street'].str.contains(' Ext'), 'Road_Type'] = 'Highway'\n",
    "df.loc[df['Street'].str.contains(' Expy'), 'Road_Type'] = 'Highway'\n",
    "df.loc[df['Street'].str.contains(' Tpk'), 'Road_Type'] = 'Highway'\n",
    "df.loc[df['Street'].str.contains(' Connection'), 'Road_Type'] = 'Highway'\n",
    "\n",
    "\n",
    "#df.loc[df['Street'].str.contains(''), 'Road_Type'] = 'NA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Road_Type\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Road_Type\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear\n",
    "df.loc[df['Weather_Condition'].str.contains('Fair', na=False), 'Weather_Condition1'] = 'Clear'\n",
    "df.loc[df['Weather_Condition'].str.contains('Clear', na=False), 'Weather_Condition1'] = 'Clear'\n",
    "df.loc[df['Weather_Condition'].str.contains('N/A Precipitation', na=False), 'Weather_Condition1'] = 'Clear'\n",
    "\n",
    "# Cloudy\n",
    "df.loc[df['Weather_Condition'].str.contains('Cloudy', na=False), 'Weather_Condition1'] = 'Cloudy'\n",
    "df.loc[df['Weather_Condition'].str.contains('Clouds', na=False), 'Weather_Condition1'] = 'Cloudy'\n",
    "df.loc[df['Weather_Condition'].str.contains('Overcast', na=False), 'Weather_Condition1'] = 'Cloudy'\n",
    "\n",
    "#Fog/Haze\n",
    "df.loc[df['Weather_Condition'].str.contains('Fog', na=False), 'Weather_Condition1'] = 'Fog/Haze'\n",
    "df.loc[df['Weather_Condition'].str.contains('Smoke', na=False), 'Weather_Condition1'] = 'Fog/Haze'\n",
    "df.loc[df['Weather_Condition'].str.contains('Dust', na=False), 'Weather_Condition1'] = 'Fog/Haze'\n",
    "df.loc[df['Weather_Condition'].str.contains('Haze', na=False), 'Weather_Condition1'] = 'Fog/Haze'\n",
    "df.loc[df['Weather_Condition'].str.contains('Sand', na=False), 'Weather_Condition1'] = 'Fog/Haze'\n",
    "\n",
    "#Rain\n",
    "df.loc[df['Weather_Condition'].str.contains('Rain', na=False), 'Weather_Condition1'] = 'Rain'\n",
    "df.loc[df['Weather_Condition'].str.contains('Mist', na=False), 'Weather_Condition1'] = 'Rain'\n",
    "df.loc[df['Weather_Condition'].str.contains('Drizzle', na=False), 'Weather_Condition1'] = 'Rain'\n",
    "df.loc[df['Weather_Condition'].str.contains('Shower', na=False), 'Weather_Condition1'] = 'Rain'\n",
    "\n",
    "# Thunder Storm\n",
    "df.loc[df['Weather_Condition'].str.contains('Thunder', na=False), 'Weather_Condition1'] = 'Thunder Storm'\n",
    "df.loc[df['Weather_Condition'].str.contains('T-Storm', na=False), 'Weather_Condition1'] = 'Thunder Storm'\n",
    "\n",
    "# Wintery Mix\n",
    "df.loc[df['Weather_Condition'].str.contains('Wintry', na=False), 'Weather_Condition1'] = 'Wintery Mix'\n",
    "df.loc[df['Weather_Condition'].str.contains('Icy', na=False), 'Weather_Condition1'] = 'Wintery Mix'\n",
    "df.loc[df['Weather_Condition'].str.contains('Ice', na=False), 'Weather_Condition1'] = 'Wintery Mix'\n",
    "df.loc[df['Weather_Condition'].str.contains('Snow', na=False), 'Weather_Condition1'] = 'Wintery Mix'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Weather_Condition1\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Weather_Condition1\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['Severity'] == 1, 'Init_Severity'] = 0\n",
    "df.loc[df['Severity'] == 2, 'Init_Severity'] = 0\n",
    "df.loc[df['Severity'] == 3, 'Init_Severity'] = 1\n",
    "df.loc[df['Severity'] == 4, 'Init_Severity'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Init_Severity\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub = df.loc[:, [ 'Severity', 'Init_Severity', 'Distance(mi)', 'Side', 'Temperature(F)', 'Humidity(%)', 'Pressure(in)',\n",
    "       'Visibility(mi)', 'Wind_Speed(mph)',\n",
    "       'Precipitation(in)', 'Weather_Condition1', 'Amenity', 'Bump', 'Crossing',\n",
    "       'Give_Way', 'Junction', 'No_Exit', 'Railway', 'Roundabout', 'Station',\n",
    "       'Stop', 'Traffic_Calming', 'Traffic_Signal', 'Turning_Loop',\n",
    "       'Sunrise_Sunset', 'Civil_Twilight', 'Nautical_Twilight',\n",
    "       'Astronomical_Twilight', 'Road_Type']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub = df_sub.dropna(subset=['Weather_Condition1', 'Wind_Speed(mph)', 'Humidity(%)', \n",
    "                               'Temperature(F)', 'Pressure(in)', 'Visibility(mi)', 'Road_Type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub[\"Weather_Condition1\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub[\"Precipitation(in)\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub[\"Precipitation(in)\"].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub[\"Precipitation(in)\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_cols_to_dum = ['Side',\n",
    "    'Weather_Condition1',\n",
    "    'Amenity',\n",
    "    'Bump', \n",
    "    'Crossing',\n",
    "    'Give_Way',\n",
    "    'Junction', \n",
    "    'No_Exit', \n",
    "    'Railway', \n",
    "    'Roundabout', \n",
    "    'Station',\n",
    "    'Stop', \n",
    "    'Traffic_Calming', \n",
    "    'Traffic_Signal', \n",
    "    'Turning_Loop',\n",
    "    'Sunrise_Sunset', \n",
    "    'Civil_Twilight', \n",
    "    'Nautical_Twilight',\n",
    "    'Astronomical_Twilight',\n",
    "    'Road_Type']\n",
    "\n",
    "# get dums\n",
    "dums_linear = pd.get_dummies(df_sub.loc[:, obj_cols_to_dum], drop_first=True)\n",
    "dums_other = pd.get_dummies(df_sub.loc[:, obj_cols_to_dum], drop_first=False)\n",
    "\n",
    "#concat\n",
    "df_sub_linear = pd.concat([df_sub, dums_linear], axis=1)\n",
    "df_sub_other = pd.concat([df_sub, dums_other], axis=1)\n",
    "\n",
    "#drop original\n",
    "df_sub_linear = df_sub_linear.drop(obj_cols_to_dum, axis=1)\n",
    "df_sub_other = df_sub_other.drop(obj_cols_to_dum, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mild_linear = df_sub_linear.loc[~(df['Severity'] == 3) & ~(df['Severity'] == 4)]\n",
    "df_mild_other = df_sub_other.loc[~(df['Severity'] == 3) & ~(df['Severity'] == 4)]\n",
    "df_severe_linear = df_sub_linear.loc[~(df['Severity'] == 1) & ~(df['Severity'] == 2)]\n",
    "df_severe_other = df_sub_other.loc[~(df['Severity'] == 1) & ~(df['Severity'] == 2)]\n",
    "\n",
    "df_mild_linear = df_mild_linear.drop([\"Init_Severity\"], axis=1)\n",
    "df_mild_other = df_mild_other.drop([\"Init_Severity\"], axis=1)\n",
    "df_severe_linear = df_severe_linear.drop([\"Init_Severity\"], axis=1)\n",
    "df_severe_other = df_severe_other.drop([\"Init_Severity\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub_other = df_sub_other.drop([\"Severity\"], axis=1)\n",
    "df_sub_linear = df_sub_linear.drop([\"Severity\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub_other.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub_other.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "sns.heatmap(df_sub_other.corr())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub_linear.groupby(\"Init_Severity\").size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get pandas columns for prediction\n",
    "target = df_sub_linear[\"Init_Severity\"]\n",
    "features = df_sub_linear.drop([\"Init_Severity\"], axis=1)\n",
    "\n",
    "# convert to lists/arrays (MUST HAPPEN)\n",
    "X = np.array(features)\n",
    "y = np.array(target)\n",
    "\n",
    "# train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = LogisticRegression()\n",
    "reg.fit(X_train, y_train)\n",
    "\n",
    "#get predictions\n",
    "in_sample_preds = reg.predict(X_train)\n",
    "out_sample_preds = reg.predict(X_test)\n",
    "\n",
    "# get evaluation report\n",
    "print(\"Logistic Classifier:\")\n",
    "print(\"Classification Report - In Sample\")\n",
    "print(classification_report(y_train, in_sample_preds))\n",
    "print()\n",
    "print(\"Confusion Matrix - In Sample\")\n",
    "print(confusion_matrix(y_train, in_sample_preds))\n",
    "print()\n",
    "print()\n",
    "print(\"Classification Report - Out Sample\")\n",
    "print(classification_report(y_test, out_sample_preds))\n",
    "print()\n",
    "print(\"Confusion Matrix - Out Sample\")\n",
    "print(confusion_matrix(y_test, out_sample_preds))\n",
    "\n",
    "# get probabilities for the ROC curve\n",
    "preds = reg.predict_proba(X_test)[:,1]\n",
    "fpr, tpr, threshold = roc_curve(y_test, preds)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# method I: plt\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.title('ROC Curve')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get pandas columns for prediction\n",
    "target = df_sub_other[\"Init_Severity\"]\n",
    "features = df_sub_other.drop([\"Init_Severity\"], axis=1)\n",
    "\n",
    "# convert to lists/arrays (MUST HAPPEN)\n",
    "X = np.array(features)\n",
    "y = np.array(target)\n",
    "\n",
    "# train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "dt = DecisionTreeClassifier(random_state=18)\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "#get predictions\n",
    "in_sample_preds = dt.predict(X_train)\n",
    "out_sample_preds = dt.predict(X_test)\n",
    "\n",
    "# get evaluation report\n",
    "print(\"Decision Tree Classifier:\")\n",
    "print(\"Classification Report - In Sample\")\n",
    "print(classification_report(y_train, in_sample_preds))\n",
    "print()\n",
    "print(\"Confusion Matrix - In Sample\")\n",
    "print(confusion_matrix(y_train, in_sample_preds))\n",
    "print()\n",
    "print()\n",
    "print(\"Classification Report - Out Sample\")\n",
    "print(classification_report(y_test, out_sample_preds))\n",
    "print()\n",
    "print(\"Confusion Matrix - Out Sample\")\n",
    "print(confusion_matrix(y_test, out_sample_preds))\n",
    "\n",
    "# get probabilities for the ROC curve\n",
    "preds = dt.predict_proba(X_test)[:,1]\n",
    "fpr, tpr, threshold = roc_curve(y_test, preds)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# method I: plt\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.title('ROC Curve')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "rf = RandomForestClassifier(random_state=18, n_estimators=100)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "#get predictions\n",
    "in_sample_preds = rf.predict(X_train)\n",
    "out_sample_preds = rf.predict(X_test)\n",
    "\n",
    "# get evaluation report\n",
    "print(\"Random Forest Classifier:\")\n",
    "print(\"Classification Report - In Sample\")\n",
    "print(classification_report(y_train, in_sample_preds))\n",
    "print()\n",
    "print(\"Confusion Matrix - In Sample\")\n",
    "print(confusion_matrix(y_train, in_sample_preds))\n",
    "print()\n",
    "print()\n",
    "print(\"Classification Report - Out Sample\")\n",
    "print(classification_report(y_test, out_sample_preds))\n",
    "print()\n",
    "print(\"Confusion Matrix - Out Sample\")\n",
    "print(confusion_matrix(y_test, out_sample_preds))\n",
    "\n",
    "# get probabilities for the ROC curve\n",
    "preds = rf.predict_proba(X_test)[:,1]\n",
    "fpr, tpr, threshold = roc_curve(y_test, preds, pos_label=2)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# method I: plt\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.title('ROC Curve')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()\n",
    "\n",
    "pd.DataFrame(list(zip(features.columns, rf.feature_importances_))).sort_values(by=1, ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "ada = AdaBoostClassifier(random_state=18)\n",
    "ada.fit(X_train, y_train)\n",
    "\n",
    "#get predictions\n",
    "in_sample_preds = ada.predict(X_train)\n",
    "out_sample_preds = ada.predict(X_test)\n",
    "\n",
    "# get evaluation report\n",
    "print(\"Ada Boost Classifier:\")\n",
    "print(\"Classification Report - In Sample\")\n",
    "print(classification_report(y_train, in_sample_preds))\n",
    "print()\n",
    "print(\"Confusion Matrix - In Sample\")\n",
    "print(confusion_matrix(y_train, in_sample_preds))\n",
    "print()\n",
    "print()\n",
    "print(\"Classification Report - Out Sample\")\n",
    "print(classification_report(y_test, out_sample_preds))\n",
    "print()\n",
    "print(\"Confusion Matrix - Out Sample\")\n",
    "print(confusion_matrix(y_test, out_sample_preds))\n",
    "\n",
    "# get probabilities for the ROC curve\n",
    "preds = ada.predict_proba(X_test)[:,1]\n",
    "fpr, tpr, threshold = roc_curve(y_test, preds)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# method I: plt\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.title('ROC Curve')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "gb = GradientBoostingClassifier(random_state=18)\n",
    "gb.fit(X_train, y_train)\n",
    "\n",
    "#get predictions\n",
    "in_sample_preds = gb.predict(X_train)\n",
    "out_sample_preds = gb.predict(X_test)\n",
    "\n",
    "# get evaluation report\n",
    "print(\"GradientBoosting Classifier:\")\n",
    "print(\"Classification Report - In Sample\")\n",
    "print(classification_report(y_train, in_sample_preds))\n",
    "print()\n",
    "print(\"Confusion Matrix - In Sample\")\n",
    "print(confusion_matrix(y_train, in_sample_preds))\n",
    "print()\n",
    "print()\n",
    "print(\"Classification Report - Out Sample\")\n",
    "print(classification_report(y_test, out_sample_preds))\n",
    "print()\n",
    "print(\"Confusion Matrix - Out Sample\")\n",
    "print(confusion_matrix(y_test, out_sample_preds))\n",
    "\n",
    "# get probabilities for the ROC curve\n",
    "preds = gb.predict_proba(X_test)[:,1]\n",
    "fpr, tpr, threshold = roc_curve(y_test, preds)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# method I: plt\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.title('ROC Curve')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "xgb = XGBClassifier(random_state=18)\n",
    "xgb.fit(X_train, y_train)\n",
    "\n",
    "#get predictions\n",
    "in_sample_preds = xgb.predict(X_train)\n",
    "out_sample_preds = xgb.predict(X_test)\n",
    "\n",
    "# get evaluation report\n",
    "print(\"XG Boost Classifier:\")\n",
    "print(\"Classification Report - In Sample\")\n",
    "print(classification_report(y_train, in_sample_preds))\n",
    "print()\n",
    "print(\"Confusion Matrix - In Sample\")\n",
    "print(confusion_matrix(y_train, in_sample_preds))\n",
    "print()\n",
    "print()\n",
    "print(\"Classification Report - Out Sample\")\n",
    "print(classification_report(y_test, out_sample_preds))\n",
    "print()\n",
    "print(\"Confusion Matrix - Out Sample\")\n",
    "print(confusion_matrix(y_test, out_sample_preds))\n",
    "\n",
    "# get probabilities for the ROC curve\n",
    "preds = xgb.predict_proba(X_test)[:,1]\n",
    "fpr, tpr, threshold = roc_curve(y_test, preds)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# method I: plt\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.title('ROC Curve')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
